# ChatGPT ç®€å•å¯¹è¯ç¤ºä¾‹
# ä½¿ç”¨ OpenAI GPT æ¨¡å‹è¿›è¡Œç®€å•é—®ç­”

name: "ChatGPT Simple Demo"

# å…¨å±€é…ç½®
global:
  debug: true

# å‡­è¯é…ç½®ï¼ˆéœ€è¦å¡«å…¥ä½ çš„ API Keyï¼‰
credentials:
  - id: "openai-key"
    name: "OpenAI API Key"
    type: "openai"
    data:
      apiKey: "${OPENAI_API_KEY}"  # ä»ç¯å¢ƒå˜é‡è¯»å–

nodes:
  # 1. è§¦å‘å™¨
  - name: "Start"
    type: "manual"
    parameters:
      question: "è¯·ç”¨ç®€å•çš„è¯­è¨€è§£é‡Šä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ"
      language: "ä¸­æ–‡"

  # 2. æ„å»ºæç¤ºè¯
  - name: "BuildPrompt"
    type: "js"
    parameters:
      code: |
        const { question, language } = input;
        
        return {
          systemPrompt: `ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„AIåŠ©æ‰‹ã€‚è¯·ç”¨${language}å›ç­”é—®é¢˜ã€‚
          å›ç­”è¦æ±‚ï¼š
          - ç®€æ´æ˜äº†
          - ä¸¾ä¾‹è¯´æ˜
          - é€‚åˆæ™®é€šäººç†è§£`,
          userQuestion: question,
          timestamp: new Date().toISOString()
        };

  # 3. è°ƒç”¨ ChatGPT
  - name: "CallGPT"
    type: "llm"
    credential_id: "openai-key"
    parameters:
      provider: "openai"
      model: "gpt-4o-mini"  # æˆ– "gpt-4", "gpt-3.5-turbo"
      temperature: 0.7
      max_tokens: 1000
      messages:
        - role: "system"
          content: "={{ $P.systemPrompt }}"
        - role: "user"
          content: "={{ $P.userQuestion }}"

  # 4. å¤„ç†å“åº”
  - name: "ProcessResponse"
    type: "js"
    parameters:
      code: |
        // AI å“åº”
        const aiResponse = input;
        
        // æå–å†…å®¹
        const content = aiResponse.choices?.[0]?.message?.content 
          || aiResponse.content 
          || aiResponse;
        
        return {
          success: true,
          question: $BuildPrompt.output.userQuestion,
          answer: content,
          model: aiResponse.model || 'unknown',
          usage: aiResponse.usage || {},
          processedAt: new Date().toISOString()
        };

  # 5. æ ¼å¼åŒ–è¾“å‡º
  - name: "FormatOutput"
    type: "js"
    parameters:
      code: |
        const result = input;
        
        // æ ¼å¼åŒ–ä¸ºæ˜“è¯»æ ¼å¼
        const formatted = `
=== AI é—®ç­”ç»“æœ ===

ğŸ“ é—®é¢˜: ${result.question}

ğŸ¤– å›ç­”:
${result.answer}

ğŸ“Š ä½¿ç”¨ç»Ÿè®¡:
- æ¨¡å‹: ${result.model}
- è¾“å…¥Token: ${result.usage.prompt_tokens || 'N/A'}
- è¾“å‡ºToken: ${result.usage.completion_tokens || 'N/A'}
- æ€»Token: ${result.usage.total_tokens || 'N/A'}

â° å¤„ç†æ—¶é—´: ${result.processedAt}
        `.trim();
        
        return {
          ...result,
          formattedOutput: formatted
        };

connections:
  Start:
    - - { node: "BuildPrompt" }
  BuildPrompt:
    - - { node: "CallGPT" }
  CallGPT:
    - - { node: "ProcessResponse" }
  ProcessResponse:
    - - { node: "FormatOutput" }
